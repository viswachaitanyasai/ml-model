{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets pandas scikit-learn\n",
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready the Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../review_data/dataset_7(senti).csv')\n",
    "\n",
    "# Convert sentiment labels to numerical values\n",
    "label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "df['Sentiment'] = df['Sentiment'].map(label_map)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Sentiment'])\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Review'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize in batches\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, batch_size=batch_size)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, batch_size=batch_size)\n",
    "\n",
    "# Rename 'Sentiment' column to 'labels' to match the expected input key\n",
    "train_dataset = train_dataset.rename_column(\"Sentiment\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"Sentiment\", \"labels\")\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=20,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     warmup_steps=2000,\n",
    "#     weight_decay=0.1,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=100,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=1e-4,\n",
    "#     fp16=True,  \n",
    "#     gradient_accumulation_steps=4,\n",
    "#     lr_scheduler_type=\"constant_with_warmup\",  \n",
    "#     save_total_limit=3, \n",
    "#     gradient_checkpointing=True,  \n",
    "#     report_to=\"none\",\n",
    "# )\n",
    "\n",
    "# Initialize the Trainer\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Test Accuracy: {eval_result['eval_accuracy']}\")\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trainded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../ml_trained_model/roberta_senti'\n",
    "file_path = os.path.join(directory)\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created.\")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(directory)\n",
    "tokenizer.save_pretrained(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../review_data/dataset_7(senti).csv', on_bad_lines='skip', quoting=csv.QUOTE_ALL)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error parsing CSV file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Drop rows with missing values in 'Sentiment' and 'Review'\n",
    "df = df.dropna(subset=['Sentiment', 'Review'])\n",
    "\n",
    "# Convert sentiment labels to numerical values\n",
    "def map_sentiment_to_labels(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    elif sentiment == 'neutral':\n",
    "        return 1\n",
    "    elif sentiment == 'positive':\n",
    "        return 2\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sentiment label: {sentiment}\")\n",
    "\n",
    "df['labels'] = df['Sentiment'].apply(map_sentiment_to_labels)\n",
    "\n",
    "# Randomly select 500 reviews for testing\n",
    "test_df = df.sample(n=500, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Review'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize in batches\n",
    "batch_size = 1000\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, batch_size=batch_size)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Load the model\n",
    "model = RobertaForSequenceClassification.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate(model, dataset):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        inputs = {key: dataset[key][i].unsqueeze(0) for key in ['input_ids', 'attention_mask']}\n",
    "        labels = dataset['labels'][i].unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        predictions = np.argmax(outputs.logits.detach().numpy(), axis=1)\n",
    "        all_predictions.append(predictions[0])\n",
    "        all_labels.append(labels.numpy()[0])\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluate(model, test_dataset)\n",
    "print(f\"Testing Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Accuracy: 0.9660"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single line sentence Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "model = RobertaForSequenceClassification.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "\n",
    "sample_review = \"0% quality , bo touch work total pass waste phone\"\n",
    "\n",
    "# Tokenize the sample review\n",
    "inputs = tokenizer(sample_review, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Perform prediction\n",
    "outputs = model(**inputs)\n",
    "predictions = np.argmax(outputs.logits.detach().numpy(), axis=1)\n",
    "\n",
    "# Map numerical predictions back to sentiment labels\n",
    "label_map = {2: 'positive', 1: 'neutral', 0: 'negative'}\n",
    "predicted_sentiment = label_map[predictions[0]]\n",
    "print(f\"Predicted sentiment: {predicted_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array of sentence Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test strings\n",
    "test_strings = [\n",
    "    \"This product is amazing!\",\n",
    "    \"disappoint with this purchase\",\n",
    "    \"Value for money\",\n",
    "    \"bad\",\n",
    "    \"Great value for the price\",\n",
    "    \"Product worse\",\n",
    "    \"Sucks, I wanna die\",\n",
    "    \"I want to get another one its so good\",\n",
    "    \"Worse\",\n",
    "    \"sometim game answer question correctli alexa say got wrong answer like turn dont light away home\",\n",
    "    \"abl\",\n",
    "    \"Not bad\",\n",
    "    \"Good\",\n",
    "    \"Sure, the movie wasn't *awful*, but it was far from a masterpiece.\",\n",
    "    \"I can't believe they won the game! They totally choked in the last quarter, though.\",\n",
    "    \"Don't get me wrong, the food was good, but the service was painfully slow.\",\n",
    "    \"They say they improved the product, but I haven't noticed a difference yet.\",\n",
    "    \"Lucky me, I found a parking spot right in front of the store.\",\n",
    "    \"It's whatever. I guess the movie was okay.\",\n",
    "    \"That was a close one! Glad we pulled through in the end.\",\n",
    "    \"Eye roll. This new update is just a bunch of bugs.\",\n",
    "    \"Not bad for a first try! I can see potential here.\",\n",
    "    \"While the graphics were impressive, the story felt a bit lacking.\"\n",
    "]\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "model = RobertaForSequenceClassification.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(model, tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = np.argmax(outputs.logits.detach().numpy(), axis=1)\n",
    "    return predictions[0]\n",
    "\n",
    "# Map numerical predictions back to sentiment labels\n",
    "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "# Predict sentiment for each test string\n",
    "for text in test_strings:\n",
    "    sentiment_label = predict_sentiment(model, tokenizer, text)\n",
    "    predicted_sentiment = label_map[sentiment_label]\n",
    "    print(f\"Review: {text}\")\n",
    "    print(f\"Predicted sentiment: {predicted_sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV file analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "model = RobertaForSequenceClassification.from_pretrained('../ml_trained_model/roberta_senti')\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(model, tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = np.argmax(outputs.logits.detach().numpy(), axis=1)\n",
    "    return predictions[0]  # Return single prediction, not numpy array\n",
    "\n",
    "# Map numerical predictions back to sentiment labels\n",
    "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../review_data/dataset_7.csv')\n",
    "\n",
    "# Initialize counters\n",
    "total_reviews = len(df)\n",
    "processed_reviews = 0\n",
    "predicted_sentiments = []\n",
    "\n",
    "# Predict sentiment for each review and store the results\n",
    "for index, row in df.iterrows():\n",
    "    sentiment_label = predict_sentiment(model, tokenizer, row['Review'])\n",
    "    predicted_sentiment = label_map[sentiment_label]\n",
    "    predicted_sentiments.append(predicted_sentiment)\n",
    "    \n",
    "    processed_reviews += 1\n",
    "    if processed_reviews % 1000 == 0:\n",
    "        print(f\"Progress: {processed_reviews}/{total_reviews} reviews processed\")\n",
    "\n",
    "# Add predicted sentiments to dataframe\n",
    "df['Sentiment'] = predicted_sentiments\n",
    "\n",
    "# Write the results to a new CSV file\n",
    "df.to_csv('../review_data/dataset_7(senti)_roberta.csv', index=False)\n",
    "df.to_csv('../analyzed_data/roberta_analyzed_data.csv', index=False)\n",
    "\n",
    "print(\"Sentiment prediction completed and saved to 'reviews_with_sentiment.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
